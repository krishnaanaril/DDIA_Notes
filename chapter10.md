# Summary

In this chapter we explored the topic of batch processing. We started by looking at
Unix tools such as awk , grep , and sort , and we saw how the design philosophy of
those tools is carried forward into MapReduce and more recent dataflow engines.
Some of those design principles are that inputs are immutable, outputs are intended
to become the input to another (as yet unknown) program, and complex problems
are solved by composing small tools that “do one thing well.”

In the Unix world, the uniform interface that allows one program to be composed
with another is files and pipes; in MapReduce, that interface is a distributed filesys‐
tem. We saw that dataflow engines add their own pipe-like data transport mecha‐
nisms to avoid materializing intermediate state to the distributed filesystem, but the
initial input and final output of a job is still usually HDFS.

The two main problems that distributed batch processing frameworks need to solve
are:

Partitioning
In MapReduce, mappers are partitioned according to input file blocks. The out‐
put of mappers is repartitioned, sorted, and merged into a configurable number
of reducer partitions. The purpose of this process is to bring all the related data—
e.g., all the records with the same key—together in the same place.
Post-MapReduce dataflow engines try to avoid sorting unless it is required, but
they otherwise take a broadly similar approach to partitioning.

Fault tolerance
MapReduce frequently writes to disk, which makes it easy to recover from an
individual failed task without restarting the entire job but slows down execution
in the failure-free case. Dataflow engines perform less materialization of inter‐
mediate state and keep more in memory, which means that they need to recom‐
pute more data if a node fails. Deterministic operators reduce the amount of data
that needs to be recomputed.

We discussed several join algorithms for MapReduce, most of which are also inter‐
nally used in MPP databases and dataflow engines. They also provide a good illustra‐
tion of how partitioned algorithms work:

Sort-merge joins
Each of the inputs being joined goes through a mapper that extracts the join key.
By partitioning, sorting, and merging, all the records with the same key end up
going to the same call of the reducer. This function can then output the joined
records.

Broadcast hash joins
One of the two join inputs is small, so it is not partitioned and it can be entirely
loaded into a hash table. Thus, you can start a mapper for each partition of the
large join input, load the hash table for the small input into each mapper, and
then scan over the large input one record at a time, querying the hash table for
each record.

Partitioned hash joins
If the two join inputs are partitioned in the same way (using the same key, same
hash function, and same number of partitions), then the hash table approach can
be used independently for each partition.

Distributed batch processing engines have a deliberately restricted programming
model: callback functions (such as mappers and reducers) are assumed to be stateless
and to have no externally visible side effects besides their designated output. This
restriction allows the framework to hide some of the hard distributed systems prob‐
lems behind its abstraction: in the face of crashes and network issues, tasks can be
retried safely, and the output from any failed tasks is discarded. If several tasks for a
partition succeed, only one of them actually makes its output visible.

Thanks to the framework, your code in a batch processing job does not need to worry
about implementing fault-tolerance mechanisms: the framework can guarantee that
the final output of a job is the same as if no faults had occurred, even though in real‐
ity various tasks perhaps had to be retried. These reliable semantics are much stron‐
ger than what you usually have in online services that handle user requests and that
write to databases as a side effect of processing a request.

The distinguishing feature of a batch processing job is that it reads some input data
and produces some output data, without modifying the input—in other words, the
output is derived from the input. Crucially, the input data is bounded: it has a known,
fixed size (for example, it consists of a set of log files at some point in time, or a snap‐shot of a database’s contents). Because it is bounded, a job knows when it has finished reading the entire input, and so a job eventually completes when it is done.

In the next chapter, we will turn to stream processing, in which the input is unboun‐
ded—that is, you still have a job, but its inputs are never-ending streams of data. In
this case, a job is never complete, because at any time there may still be more work
coming in. We shall see that stream and batch processing are similar in some
respects, but the assumption of unbounded streams also changes a lot about how we
build systems.